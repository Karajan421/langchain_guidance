{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "823bb6e4-5f01-4ef2-a794-6e997cbfd8f1",
   "metadata": {},
   "source": [
    "## Define a tool\n",
    "We define a search tool with GoogleSerperAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b92049-03e4-466c-824a-f46de7490a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "os.environ[\"SERPER_API_KEY\"] = 'fbac5061b434c6b0e5f55968258b144209993ab2'\n",
    "search = GoogleSerperAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "llama = guidance.llms.LlamaCpp(\n",
    "    model =\"/home/karajan/Downloads/open-llama-3b-q8_0.bin\",\n",
    "    tokenizer = \"openaccess-ai-collective/manticore-13b-chat-pyg\",\n",
    "    before_role = \"<|\",\n",
    "    after_role = \"|>\",\n",
    "    n_gpu_layers=300,\n",
    "    n_threads=12,\n",
    "    caching=False, )\n",
    "guidance.llm = llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "model_type = \"LlamaCpp\"\n",
    "model_path = \"/home/karajan/Downloads/open-llama-3b-q8_0.bin\"\n",
    "model_n_ctx =1000\n",
    "target_source_chunks = 4\n",
    "n_gpu_layers = 500\n",
    "use_mlock = 0\n",
    "n_batch = os.environ.get('N_BATCH') if os.environ.get('N_BATCH') != None else 512\n",
    "callbacks = []\n",
    "qa_prompt = \"\"\n",
    "llm = LlamaCpp(model_path=model_path, n_ctx=model_n_ctx, callbacks=callbacks, verbose=False,n_gpu_layers=n_gpu_layers, use_mlock=use_mlock,top_p=0.9, n_batch=n_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "import re \n",
    "from colorama import Fore, Style\n",
    "\n",
    "retriver=\"\"\n",
    "EMBEDDINGS_MAP = {\n",
    "    **{name: HuggingFaceInstructEmbeddings for name in [\"hkunlp/instructor-xl\", \"hkunlp/instructor-large\"]},\n",
    "    **{name: HuggingFaceEmbeddings for name in [\"all-MiniLM-L6-v2\", \"sentence-t5-xxl\"]}\n",
    "}\n",
    "EMBEDDINGS_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove line breaks\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def load_unstructured_document(document: str) -> list[Document]:\n",
    "    with open(document, 'r') as file:\n",
    "        text = file.read()\n",
    "    title = os.path.basename(document)\n",
    "    return [Document(page_content=text, metadata={\"title\": title})]\n",
    "\n",
    "def split_documents(documents: list[Document], chunk_size: int = 250, chunk_overlap: int = 20) -> list[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "def ingest_file(file_path):\n",
    "        documents = load_unstructured_document(file_path)\n",
    "        documents = split_documents(documents, chunk_size=250, chunk_overlap=100)\n",
    "        EmbeddingsModel = EMBEDDINGS_MAP.get(EMBEDDINGS_MODEL)\n",
    "        if EmbeddingsModel is None:\n",
    "            raise ValueError(f\"Invalid embeddings model: {EMBEDDINGS_MODEL}\")\n",
    "        \n",
    "        model_kwargs = {\"device\": \"cuda:0\"} if EmbeddingsModel == HuggingFaceInstructEmbeddings else {}\n",
    "        embedding = EmbeddingsModel(model_name=EMBEDDINGS_MODEL, model_kwargs=model_kwargs)\n",
    "        vectordb = Chroma.from_documents(documents=documents, embedding=embedding)\n",
    "\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "        print(file_path)\n",
    "        print(retriever)\n",
    "\n",
    "        return retriever, file_path\n",
    "\n",
    "\n",
    "def checkQuestion(question: str, retriever, llm):\n",
    "    global qa_prompt\n",
    "    DOCUMENTS_SUMMARY_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant, and you've been given a list of documents. These documents are presented in a continuous string, separated by spaces. Your task is to parse this string, identify individual documents, and create a summarized list describing the content of each document.\n",
    "Documents:{context}\n",
    "### Response:\"\"\"\n",
    "    QUESTION_CHECK_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant who uses document information to answer questions. Given the following pieces of context, determine if there are any elements related to the question in the context. To assist me in this task, you have access to a vector database context that contains various documents related to different topics.Don't forget you MUST answer with 'yes' or 'no'\n",
    " \n",
    "Context:{context}\n",
    "Question: Do you think it would be possible to infer an answer to \"\"{question}\"\" from the information in the context? You MUST include'yes' or 'no' in your answer.\n",
    "### Response: \"\"\"\n",
    "    question = question.replace(\"Action Input: \", \"\")\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "    # Answer the question\n",
    "    answer_data = qa({\"query\": question})\n",
    "\n",
    "    # Check if 'answer' is in answer_data, if not print it in bold red\n",
    "    if 'result' not in answer_data:\n",
    "        print(f\"\\033[1;31m{answer_data}\\033[0m\")\n",
    "        return \"Issue in retrieving the answer.\"\n",
    "\n",
    "    context_documents = answer_data['source_documents']\n",
    "\n",
    "    # Combine all contexts into one\n",
    "    context = \" \".join([clean_text(doc.page_content) for doc in context_documents])\n",
    "    documents_summary_prompt = DOCUMENTS_SUMMARY_PROMPT_TEMPLATE.format(context=context)\n",
    "\n",
    "    summary = llm(documents_summary_prompt)\n",
    "\n",
    "    # Formulate the prompt for the LLM\n",
    "    question_check_prompt = QUESTION_CHECK_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "\n",
    "    print(Fore.GREEN + Style.BRIGHT + question_check_prompt + Style.RESET_ALL)\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936df03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def can_answer(question: str, retriever, llm):\n",
    "    global qa_prompt\n",
    "    question = question.replace(\"Action Input: \", \"\")\n",
    "\n",
    "    DOCUMENTS_SUMMARY_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant, and you've been given a list of documents. These documents are presented in a continuous string, separated by spaces. Your task is to parse this string, identify individual documents, and create a summarized list describing the content of each document.\n",
    "Documents:{context}\n",
    "### Response:\"\"\"\n",
    "    QUESTION_CHECK_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant who uses document information to answer questions. Given the following pieces of context, determine if there are any elements related to the question in the context. To assist me in this task, you have access to a vector database context that contains various documents related to different topics.Don't forget you MUST answer with 'yes' or 'no'\n",
    " \n",
    "Context:{context}\n",
    "Question: Do you think it would be possible to infer an answer to \"\"{question}\"\" from the information in the context? You MUST include'yes' or 'no' in your answer.\n",
    "### Response:\n",
    "\"\"\"\n",
    "    QUESTION_QA_PROMPT_TEMPLATE = \"\"\"### Human: You are an helpful assistant that tries to answer questions concisely and precisely. Your answer must ONLY be based on the context information provided. Inclue 'yes' in your answer if it's positive.\n",
    "    Context:{context}\n",
    "    Question: {question}\n",
    "    ### Assistant:\n",
    "\"\"\"\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "    # Answer the question\n",
    "    answer_data = qa({\"query\": question})\n",
    "\n",
    "    # Check if 'answer' is in answer_data, if not print it in bold red\n",
    "    if 'result' not in answer_data:\n",
    "        print(f\"\\033[1;31m{answer_data}\\033[0m\")\n",
    "        return \"Issue in retrieving the answer.\"\n",
    "\n",
    "    answer = answer_data['result']\n",
    "    context_documents = answer_data['source_documents']\n",
    "\n",
    "    # Combine all contexts into one\n",
    "    context = \" \".join([clean_text(doc.page_content) for doc in context_documents])\n",
    "    # Formulate the prompt for the LLM\n",
    "    documents_summary_prompt = DOCUMENTS_SUMMARY_PROMPT_TEMPLATE.format(context=context)\n",
    "    summary = llm(documents_summary_prompt)\n",
    "    \n",
    "    question_check_prompt = QUESTION_CHECK_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "    qa_prompt = QUESTION_QA_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "\n",
    "    print(Fore.GREEN + Style.BRIGHT + question_check_prompt + Style.RESET_ALL)\n",
    "    # Submit the prompt to the LLM directly\n",
    "    answerable = llm(question_check_prompt)\n",
    "    print(Fore.RED + Style.BRIGHT + context + Style.RESET_ALL)\n",
    "    print(Fore.RED + Style.BRIGHT + answerable + Style.RESET_ALL)\n",
    "    if \"yes\" in answerable.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever, file_patch = ingest_file(\"/home/karajan/Documents/notion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de04fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkQuestion(\"What's the wifi code\", retriever, llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_answers = ['Action', 'Final Answer']\n",
    "valid_tools = ['Google Search']\n",
    "\n",
    "\n",
    "valid_answers = ['Action', 'Final Answer']\n",
    "valid_tools = [\"Check Question\", \"Google Search\"]\n",
    "\n",
    "dict_tools = {\n",
    "    'Check Question': search,\n",
    "    'Google Search': search\n",
    "}\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "{{#system~}}\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "Google Search: A wrapper around Google Search. Useful for when you need to answer questions about current events. The input is the question to search relevant information.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Question: {{question}}\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "Thought: Let's first check our database.\n",
    "Action: Check Question\n",
    "Action Input: {{question}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Here are the relevant documents from our database:{{search question}}\n",
    "{{~/user}}address?\n",
    "\n",
    "{{#assistant~}}\n",
    "Observation: Based on the documents, I think I can reach a conclusion.\n",
    "{{#if (can_answer)}} \n",
    "Thought: I believe I can answer the question based on the information contained in the returned documents.\n",
    "Final Answer: {{gen 'answer' temperature=0.7 max_tokens=500}}\n",
    "{{else}}\n",
    "Thought: I don't think I can answer the question based on the information contained in the returned documents.\n",
    "Final Answer: I'm sorry, but I don't have sufficient information to provide an answer to this question.\n",
    "{{/if}}\n",
    "{{~/assistant}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question=\"What's the wifi network code?\"\n",
    "\n",
    "def searchQA(t):    \n",
    "    return checkQuestion(question, retriever, llm)\n",
    "\n",
    "prompt = guidance(prompt_template)\n",
    "result = prompt(question=question, search=searchQA, can_answer=can_answer(question, retriever, llm),valid_answers=valid_answers, valid_tools=valid_tools)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "116eab4f-f7b5-4428-9827-7600bd4d4cdd",
   "metadata": {},
   "source": [
    "## Let's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213706a-9b64-4d8b-b769-13b163367ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance.llm.cache.clear()\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "041d69e8-78a8-499c-a34c-1c98eea2b23a",
   "metadata": {},
   "source": [
    "### Define prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46760ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the code of the wifi?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "564b8576-0d21-4495-93c7-a3a67451782c",
   "metadata": {},
   "source": [
    "### Our agent with Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163881c-23a1-4a09-8e4d-34d849fb1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance.llm.cache.clear()\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
