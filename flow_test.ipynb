{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "823bb6e4-5f01-4ef2-a794-6e997cbfd8f1",
   "metadata": {},
   "source": [
    "## Define a tool\n",
    "We define a search tool with GoogleSerperAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b92049-03e4-466c-824a-f46de7490a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "os.environ[\"SERPER_API_KEY\"] = 'fbac5061b434c6b0e5f55968258b144209993ab2'\n",
    "search = GoogleSerperAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fb6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/karajan/labzone/llama.cpp/models/jondurbin_airoboros-7b-gpt4/jondurbin_airoborosggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size = 3615.71 MB\n",
      "llama_model_load_internal: mem required  = 1932.71 MB (+ 1026.00 MB per state)\n",
      "llama_model_load_internal: [cublas] offloading 32 layers to GPU\n",
      "llama_model_load_internal: [cublas] offloading output layer to GPU\n",
      "llama_model_load_internal: [cublas] total VRAM used: 3475 MB\n",
      "...................................................................................................\n",
      "llama_init_from_file: kv self size  = 1024.00 MB\n"
     ]
    }
   ],
   "source": [
    "import guidance\n",
    "llama = guidance.llms.LlamaCpp(\n",
    "    model =\"/home/karajan/labzone/llama.cpp/models/jondurbin_airoboros-7b-gpt4/jondurbin_airoborosggml-model-q4_0.bin\",\n",
    "    tokenizer = \"openaccess-ai-collective/manticore-13b-chat-pyg\",\n",
    "    before_role = \"<|\",\n",
    "    after_role = \"|>\",\n",
    "    n_gpu_layers=300,\n",
    "    n_threads=12,\n",
    "    caching=False, )\n",
    "guidance.llm = llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae82c552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/karajan/labzone/llama.cpp/models/jondurbin_airoboros-7b-gpt4/jondurbin_airoborosggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 1000\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.07 MB\n",
      "llama_model_load_internal: mem required  = 1932.71 MB (+ 1026.00 MB per state)\n",
      "llama_model_load_internal: [cublas] offloading 32 layers to GPU\n",
      "llama_model_load_internal: [cublas] offloading output layer to GPU\n",
      "llama_model_load_internal: [cublas] total VRAM used: 3475 MB\n",
      "...................................................................................................\n",
      "llama_init_from_file: kv self size  =  500.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "model_type = \"LlamaCpp\"\n",
    "model_path = \"/home/karajan/labzone/llama.cpp/models/jondurbin_airoboros-7b-gpt4/jondurbin_airoborosggml-model-q4_0.bin\"\n",
    "model_n_ctx =1000\n",
    "target_source_chunks = 4\n",
    "n_gpu_layers = 500\n",
    "use_mlock = 0\n",
    "n_batch = os.environ.get('N_BATCH') if os.environ.get('N_BATCH') != None else 512\n",
    "callbacks = []\n",
    "qa_prompt = \"\"\n",
    "llm = LlamaCpp(model_path=model_path, n_ctx=model_n_ctx, callbacks=callbacks, verbose=False,n_gpu_layers=n_gpu_layers, use_mlock=use_mlock,top_p=0.9, n_batch=n_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a3d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "import re \n",
    "from colorama import Fore, Style\n",
    "\n",
    "retriver=\"\"\n",
    "EMBEDDINGS_MAP = {\n",
    "    **{name: HuggingFaceInstructEmbeddings for name in [\"hkunlp/instructor-xl\", \"hkunlp/instructor-large\"]},\n",
    "    **{name: HuggingFaceEmbeddings for name in [\"all-MiniLM-L6-v2\", \"sentence-t5-xxl\"]}\n",
    "}\n",
    "EMBEDDINGS_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove line breaks\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def load_unstructured_document(document: str) -> list[Document]:\n",
    "    with open(document, 'r') as file:\n",
    "        text = file.read()\n",
    "    title = os.path.basename(document)\n",
    "    return [Document(page_content=text, metadata={\"title\": title})]\n",
    "\n",
    "def split_documents(documents: list[Document], chunk_size: int = 250, chunk_overlap: int = 20) -> list[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "def ingest_file(file_path):\n",
    "        documents = load_unstructured_document(file_path)\n",
    "        documents = split_documents(documents, chunk_size=250, chunk_overlap=100)\n",
    "        EmbeddingsModel = EMBEDDINGS_MAP.get(EMBEDDINGS_MODEL)\n",
    "        if EmbeddingsModel is None:\n",
    "            raise ValueError(f\"Invalid embeddings model: {EMBEDDINGS_MODEL}\")\n",
    "        \n",
    "        model_kwargs = {\"device\": \"cuda:0\"} if EmbeddingsModel == HuggingFaceInstructEmbeddings else {}\n",
    "        embedding = EmbeddingsModel(model_name=EMBEDDINGS_MODEL, model_kwargs=model_kwargs)\n",
    "        vectordb = Chroma.from_documents(documents=documents, embedding=embedding)\n",
    "\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "        print(file_path)\n",
    "        print(retriever)\n",
    "\n",
    "        return retriever, file_path\n",
    "\n",
    "\n",
    "def checkQuestion(question: str, retriever, llm):\n",
    "    global qa_prompt\n",
    "    DOCUMENTS_SUMMARY_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant, and you've been given a list of documents. These documents are presented in a continuous string, separated by spaces. Your task is to parse this string, identify individual documents, and create a summarized list describing the content of each document.\n",
    "Documents:{context}\n",
    "### Response:\"\"\"\n",
    "    QUESTION_CHECK_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant who uses document information to answer questions. Given the following pieces of context, determine if there are any elements related to the question in the context. To assist me in this task, you have access to a vector database context that contains various documents related to different topics.Don't forget you MUST answer with 'yes' or 'no'\n",
    " \n",
    "Context:{context}\n",
    "Question: Do you think it would be possible to infer an answer to \"\"{question}\"\" from the information in the context? You MUST include'yes' or 'no' in your answer.\n",
    "### Response: \"\"\"\n",
    "    question = question.replace(\"Action Input: \", \"\")\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "    # Answer the question\n",
    "    answer_data = qa({\"query\": question})\n",
    "\n",
    "    # Check if 'answer' is in answer_data, if not print it in bold red\n",
    "    if 'result' not in answer_data:\n",
    "        print(f\"\\033[1;31m{answer_data}\\033[0m\")\n",
    "        return \"Issue in retrieving the answer.\"\n",
    "\n",
    "    context_documents = answer_data['source_documents']\n",
    "\n",
    "    # Combine all contexts into one\n",
    "    context = \" \".join([clean_text(doc.page_content) for doc in context_documents])\n",
    "    documents_summary_prompt = DOCUMENTS_SUMMARY_PROMPT_TEMPLATE.format(context=context)\n",
    "\n",
    "    summary = llm(documents_summary_prompt)\n",
    "\n",
    "    # Formulate the prompt for the LLM\n",
    "    question_check_prompt = QUESTION_CHECK_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "\n",
    "    print(Fore.GREEN + Style.BRIGHT + question_check_prompt + Style.RESET_ALL)\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "936df03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def can_answer(question: str, retriever, llm):\n",
    "    global qa_prompt\n",
    "    question = question.replace(\"Action Input: \", \"\")\n",
    "\n",
    "    DOCUMENTS_SUMMARY_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant, and you've been given a list of documents. These documents are presented in a continuous string, separated by spaces. Your task is to parse this string, identify individual documents, and create a summarized list describing the content of each document.\n",
    "Documents:{context}\n",
    "### Response:\"\"\"\n",
    "    QUESTION_CHECK_PROMPT_TEMPLATE = \"\"\"###Instruction: You are an AI assistant who uses document information to answer questions. Given the following pieces of context, determine if there are any elements related to the question in the context. To assist me in this task, you have access to a vector database context that contains various documents related to different topics.Don't forget you MUST answer with 'yes' or 'no'\n",
    " \n",
    "Context:{context}\n",
    "Question: Do you think it would be possible to infer an answer to \"\"{question}\"\" from the information in the context? You MUST include'yes' or 'no' in your answer.\n",
    "### Response:\n",
    "\"\"\"\n",
    "    QUESTION_QA_PROMPT_TEMPLATE = \"\"\"### Human: You are an helpful assistant that tries to answer questions concisely and precisely. Your answer must ONLY be based on the context information provided. Inclue 'yes' in your answer if it's positive.\n",
    "    Context:{context}\n",
    "    Question: {question}\n",
    "    ### Assistant:\n",
    "\"\"\"\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "    # Answer the question\n",
    "    answer_data = qa({\"query\": question})\n",
    "\n",
    "    # Check if 'answer' is in answer_data, if not print it in bold red\n",
    "    if 'result' not in answer_data:\n",
    "        print(f\"\\033[1;31m{answer_data}\\033[0m\")\n",
    "        return \"Issue in retrieving the answer.\"\n",
    "\n",
    "    answer = answer_data['result']\n",
    "    context_documents = answer_data['source_documents']\n",
    "\n",
    "    # Combine all contexts into one\n",
    "    context = \" \".join([clean_text(doc.page_content) for doc in context_documents])\n",
    "    # Formulate the prompt for the LLM\n",
    "    documents_summary_prompt = DOCUMENTS_SUMMARY_PROMPT_TEMPLATE.format(context=context)\n",
    "    summary = llm(documents_summary_prompt)\n",
    "    \n",
    "    question_check_prompt = QUESTION_CHECK_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "    qa_prompt = QUESTION_QA_PROMPT_TEMPLATE.format(context=summary, question=question)\n",
    "\n",
    "    print(Fore.GREEN + Style.BRIGHT + question_check_prompt + Style.RESET_ALL)\n",
    "    # Submit the prompt to the LLM directly\n",
    "    answerable = llm(question_check_prompt)\n",
    "    print(Fore.RED + Style.BRIGHT + context + Style.RESET_ALL)\n",
    "    print(Fore.RED + Style.BRIGHT + answerable + Style.RESET_ALL)\n",
    "    if \"yes\" in answerable.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "514f5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karajan/Documents/notion.txt\n",
      "vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f2dc53a7910> search_type='similarity' search_kwargs={'k': 4}\n"
     ]
    }
   ],
   "source": [
    "retriever, file_patch = ingest_file(\"/home/karajan/Documents/notion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de04fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2358.21 ms\n",
      "llama_print_timings:      sample time =     7.10 ms /    16 runs   (    0.44 ms per token)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token)\n",
      "llama_print_timings:        eval time =   579.19 ms /    16 runs   (   36.20 ms per token)\n",
      "llama_print_timings:       total time =   621.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m###Instruction: You are an AI assistant who uses document information to answer questions. Given the following pieces of context, determine if there are any elements related to the question in the context. To assist me in this task, you have access to a vector database context that contains various documents related to different topics.Don't forget you MUST answer with 'yes' or 'no'\n",
      " \n",
      "Context:You are an AI assistant, and you've been given a list of documents. These documents are presented in a continuous string, separated by spaces. Your task is to parse this string, identify individual documents, and create a summarized list describing the content of each document.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. The first line (after the header) contains the name of the program you're running.\n",
      "2. The second line starts with \"Documents:\" which serves as the trigger for the following function to parse the string and create a summarized list.\n",
      "3. Each subsequent line after the second line represents a document, separated by spaces.\n",
      "4. The last line ends with \"What is this page?\" which is ignored during parsing since it's not part of the text to be extracted.\n",
      "\n",
      "Here's the extracted summary:\n",
      "\n",
      "```\n",
      "Documents: To open the first door press the round button Then ring at World Game We are on the 3rd floor the only ones on the landing You can ring WiFi Network Livebox3B00 Code 9Dg34Xfthne3bnWhX6 Use them What is this page Description what will this tutorial allow us to do If\n",
      "Question: Do you think it would be possible to infer an answer to \"\"What's the wifi code\"\" from the information in the context? You MUST include'yes' or 'no' in your answer.\n",
      "### Response: \u001b[0m\n",
      "To open the first door press the round button Then ring at World Game We are on the 3rd floor the only ones on the landing You can ring  WiFi Network Livebox3B00 Code 9Dg34Xfthne3bnWhX6  Use them  What is this page  What is this page  Description what will this tutorial allow us to do If youre having trouble or have questions look for the answer in the FAQ at the end of this page If it is not there contact XXXX on Slack who will answer you and complete the FAQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2358.21 ms\n",
      "llama_print_timings:      sample time =    99.03 ms /   256 runs   (    0.39 ms per token)\n",
      "llama_print_timings: prompt eval time =  2038.57 ms /   190 tokens (   10.73 ms per token)\n",
      "llama_print_timings:        eval time =  9776.18 ms /   255 runs   (   38.34 ms per token)\n",
      "llama_print_timings:       total time = 12776.44 ms\n"
     ]
    }
   ],
   "source": [
    "print(checkQuestion(\"What's the wifi code\", retriever, llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564b8552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-25319fe8-82e3-4083-9bc4-d68a63dc182b\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-25319fe8-82e3-4083-9bc4-d68a63dc182b\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
       "### Instruction:\n",
       "Answer the following questions as best you can. You have access to the following tools:\n",
       "Google Search: A wrapper around Google Search. Useful for when you need to answer questions about current events. The input is the question to search relevant information.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Question: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{question}}'>What&#x27;s the wifi network code?</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Thought: Let&#x27;s first check our database.\n",
       "Action: Check Question\n",
       "Action Input: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{question}}'>What&#x27;s the wifi network code?</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Here are the relevant documents from our database:<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{search question}}'>To open the first door press the round button Then ring at World Game We are on the 3rd floor the only ones on the landing You can ring  WiFi Network Livebox3B00 Code 9Dg34Xfthne3bnWhX6  Use them  What is this page  What is this page  Description what will this tutorial allow us to do If youre having trouble or have questions look for the answer in the FAQ at the end of this page If it is not there contact XXXX on Slack who will answer you and complete the FAQ</span></div></div>address?<div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Observation: Based on the documents, I think I can reach a conclusion.\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (can_answer)}} \n",
       "Thought: I believe I can answer the question based on the information contained in the returned documents.\n",
       "Final Answer: {{gen &#x27;answer&#x27; temperature=0.7 max_tokens=500}}\n",
       "{{else}}\n",
       "Thought: I don&#x27;t think I can answer the question based on the information contained in the returned documents.\n",
       "Final Answer: I&#x27;m sorry, but I don&#x27;t have sufficient information to provide an answer to this question.\n",
       "{{/if}}'>\n",
       "Thought: I don&#x27;t think I can answer the question based on the information contained in the returned documents.\n",
       "Final Answer: I&#x27;m sorry, but I don&#x27;t have sufficient information to provide an answer to this question.\n",
       "</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"25319fe8-82e3-4083-9bc4-d68a63dc182b\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_answers = ['Action', 'Final Answer']\n",
    "valid_tools = ['Google Search']\n",
    "\n",
    "\n",
    "valid_answers = ['Action', 'Final Answer']\n",
    "valid_tools = [\"Check Question\", \"Google Search\"]\n",
    "\n",
    "dict_tools = {\n",
    "    'Check Question': search,\n",
    "    'Google Search': search\n",
    "}\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "{{#system~}}\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "Google Search: A wrapper around Google Search. Useful for when you need to answer questions about current events. The input is the question to search relevant information.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Question: {{question}}\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "Thought: Let's first check our database.\n",
    "Action: Check Question\n",
    "Action Input: {{question}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Here are the relevant documents from our database:{{search question}}\n",
    "{{~/user}}address?\n",
    "\n",
    "{{#assistant~}}\n",
    "Observation: Based on the documents, I think I can reach a conclusion.\n",
    "{{#if (can_answer)}} \n",
    "Thought: I believe I can answer the question based on the information contained in the returned documents.\n",
    "Final Answer: {{gen 'answer' temperature=0.7 max_tokens=500}}\n",
    "{{else}}\n",
    "Thought: I don't think I can answer the question based on the information contained in the returned documents.\n",
    "Final Answer: I'm sorry, but I don't have sufficient information to provide an answer to this question.\n",
    "{{/if}}\n",
    "{{~/assistant}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question=\"What's the wifi network code?\"\n",
    "\n",
    "def searchQA(t):    \n",
    "    return checkQuestion(question, retriever, llm)\n",
    "\n",
    "prompt = guidance(prompt_template)\n",
    "result = prompt(question=question, search=searchQA, can_answer=can_answer(question, retriever, llm),valid_answers=valid_answers, valid_tools=valid_tools)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "116eab4f-f7b5-4428-9827-7600bd4d4cdd",
   "metadata": {},
   "source": [
    "## Let's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213706a-9b64-4d8b-b769-13b163367ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance.llm.cache.clear()\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "041d69e8-78a8-499c-a34c-1c98eea2b23a",
   "metadata": {},
   "source": [
    "### Define prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46760ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the code of the wifi?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "564b8576-0d21-4495-93c7-a3a67451782c",
   "metadata": {},
   "source": [
    "### Our agent with Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163881c-23a1-4a09-8e4d-34d849fb1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance.llm.cache.clear()\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
